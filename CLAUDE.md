# Personal Assistant

**A transparent, hackable AI assistant that evolves with you.**

## Philosophy

This project prioritizes **transparency over polish**. The entire system is ~1000 lines of Python and a simple React frontend—no magic, no hidden complexity. You can read every line of code that touches files, executes commands, or stores data.

You're not just an AI running inside this codebase. You *are* the assistant, and you can modify yourself: fix bugs, add features, improve skills, even rewrite the wrapper application you're running inside. This is a tool that grows with its user, not one that forces adaptation to someone else's vision.

**Core principles:**
- **Developer-native**: A proper development environment, not a chatbot bolted onto a messaging app
- **Self-improving**: Teach it something once, turn it into a reusable automation
- **Local-first**: Conversations, memory, and credentials stay on the user's machine

## What You Can Do

- **Chat** through a web interface with real-time streaming
- **Talk** using realtime voice mode — speak through the orchestrator via WebRTC
- **Execute** code, manage files, run shell commands—full Claude Code capabilities
- **Remember** context across sessions with searchable conversation history
- **Automate** workflows through custom skills (slash commands)
- **Evolve** by creating new skills and modifying your own behavior

---

## Project Structure

This project separates **public framework** from **private data** for easy sharing and environment migration:

```
assistant/                    # PUBLIC - shareable framework
├── default-skills/           # General-purpose skills (actual files)
├── default-scripts/          # General-purpose scripts (actual files)
├── default-agents/           # General-purpose agents (actual files)
├── .claude_config/           # Claude Code SDK config
│   └── skills → ../context/skills  # SDK skill discovery
├── manager/                  # Python wrapper for Claude Code SDK (~400 lines)
├── orchestrator/             # Orchestrator agent — controls Claude Code instances
│   └── providers/            # Model providers (Anthropic text, OpenAI realtime voice)
├── api/                      # FastAPI server (REST + WebSocket, ~300 lines)
├── frontend/                 # React multi-tab chat interface
├── utils/                    # Shared Python utilities (paths.py)
├── tests/                    # Test suite
├── index/                    # Vector search index (gitignored)
└── .venv/                    # Python virtual environment

context/                      # PRIVATE - Git submodule (assistant-context repo)
├── *.jsonl                   # Conversation JSONL files
├── <uuid>/                   # SDK state directories (subagents, tool-results)
├── memory/                   # Memory markdown files
├── skills/                   # Symlinks to default-skills + personalized skills
├── scripts/                  # Symlinks to default-scripts + personalized scripts
├── agents/                   # Symlinks to default-agents + personalized agents
├── secrets/                  # OAuth credentials and tokens
├── certs/                    # SSL certificates
└── .env                      # Environment variables
```

**Public/Private separation:**
- `default-skills/`, `default-scripts/`, and `default-agents/` contain general-purpose tools (shareable)
- `context/` is a Git submodule pointing to a private repo (`assistant-context`)
- `context/skills/` has symlinks to `default-skills/*` plus personalized skill folders
- `context/scripts/` has symlinks to `default-scripts/*` plus personalized scripts
- `context/agents/` has symlinks to `default-agents/*` plus personalized agents
- Swap the `context/` submodule to migrate to a new environment

`CLAUDE_CONFIG_DIR` is set to `.claude_config/` by `context/scripts/run.sh`. All code references `context/` directly via `utils/paths.py`.

---

## Reference

### The Wrapper Application

The wrapper (api + manager + orchestrator + frontend) provides a multi-tab web interface for interacting with Claude Code. The orchestrator agent can control multiple Claude Code instances simultaneously and supports both text and realtime voice modes. When running inside the wrapper, you can edit its own code—the manager, API routes, frontend components—and those changes affect the very application you're running in.

**Session IDs:** Each session has a stable `local_id` (UUID, generated by frontend, never changes) and an `sdk_session_id` (from Claude SDK, used for resume/JSONL). The `local_id` is the primary key for the session pool, tabs, and orchestrator.

Start the backend: `context/scripts/run.sh -m uvicorn api.app:create_app --factory --port 8000`

Start the frontend: `cd frontend && npm run dev`

Or use `/debug-app` which handles both and provides browser automation.

### Memory System

The `context/` folder is a Git submodule containing all private data, including the memory system:

```
context/
├── *.jsonl            # Conversation history (JSONL files)
├── .titles.json       # Custom session titles
├── <uuid>/            # SDK state dirs (subagents, tool-results)
├── memory/            # Memory files (Markdown)
│   ├── MEMORY.md      # Authoritative index (keep under 200 lines)
│   └── *.md           # Detailed topic files
├── skills/            # Symlinks to default-skills/* + personalized folders
├── scripts/           # Symlinks to default-scripts/* + personalized files
├── secrets/           # OAuth credentials and tokens
├── certs/             # SSL certificates
└── .env               # Environment variables
```

**The Shared Memory Index (`context/memory/MEMORY.md`)**

This file is the **single source of truth** for all skills, memory files, and project references. Both the orchestrator (which loads it dynamically into its prompt) and Claude Code agents rely on this index.

**Structure:**
- Keep `MEMORY.md` under 200 lines with one-line references only
- Store detailed content in separate `<topic>.md` files
- Reference format: `- filename.md — Brief description`

**Your maintenance responsibilities:**

When you make changes that affect the memory index, update `MEMORY.md` directly:
1. **Skills**: Update the Skills Reference table when skills are added, removed, or modified
2. **Memory files**: Add a reference line when creating new `<topic>.md` files
3. **Projects**: Update entries when project status changes (started, completed, abandoned)

You have full editing capabilities via Claude Code's tools—use them to keep the index accurate. The orchestrator loads this file dynamically, so your updates are immediately visible to the entire system.

**Semantic search:**

Both memory and conversation history are indexed for search via `/recall <query>`:
- Memory files: Indexed immediately when changed (file watcher)
- History: Indexed every 2 minutes (if changed)

**Note**: `.claude_config/projects/<mangled>/` symlinks to `context/` for SDK compatibility.

### Voice Mode (Realtime)

The orchestrator supports a realtime voice mode powered by the OpenAI Realtime API via WebRTC. Audio flows directly between the browser and OpenAI for low latency; the backend only handles signaling, tool execution, and persistence.

**Architecture:**
- Frontend establishes a WebRTC connection to OpenAI using an ephemeral token from the backend (`POST /api/orchestrator/voice/session`)
- Audio streams directly between browser ↔ OpenAI (sub-100ms latency)
- The frontend mirrors all OpenAI data channel events to the backend via the orchestrator WebSocket (`voice_event` messages)
- The backend processes tool calls and sends commands back (`voice_command` messages) for the frontend to forward to OpenAI
- Server-side VAD (voice activity detection) — no push-to-talk needed

**Key files:**
- `api/routes/voice.py` — Ephemeral token endpoint (exchanges `OPENAI_API_KEY` for a short-lived token)
- `orchestrator/providers/openai_voice.py` — `OpenAIVoiceProvider` that translates OpenAI Realtime events into `OrchestratorEvent`s
- `orchestrator/session.py` — Voice session lifecycle, tool execution, JSONL persistence
- `frontend/src/hooks/useVoiceSession.ts` — WebRTC connection management (SDP exchange, mic, data channel)
- `frontend/src/hooks/useVoiceOrchestrator.ts` — Bridges the WebRTC session and orchestrator WebSocket
- `frontend/src/components/VoiceButton.tsx` — Mic toggle UI with states: off, connecting, active, speaking, thinking, tool_use, error
- `frontend/src/api/voice.ts` — API client for ephemeral token and SDP exchange

**Environment:** Requires `OPENAI_API_KEY` set in the environment. Model: `gpt-realtime`, voice: `cedar`.

**Tool sharing:** Both text (Anthropic) and voice (OpenAI) modes use the same `ToolRegistry`. `get_definitions()` returns Anthropic format; `get_openai_definitions()` returns OpenAI function-calling format.

**JSONL persistence:** Voice turns are saved with `"source": "voice_transcription"` / `"voice_response"` fields. User transcripts are prefixed with `[voice]`. Interruptions are logged as `voice_interrupted` entries.

### Self-Modification

You can extend and modify your own capabilities:

- **Skills** (`context/skills/`): Create with `/scaffold-skill`, modify existing ones directly
- **Agents** (`context/agents/`): Create with `/scaffold-agent` for specialized subagents
- **Scripts** (`context/scripts/`): Shared tools any skill can reference
- **Wrapper** (`api/`, `manager/`, `frontend/`): The application code itself

Run Python scripts through the venv: `context/scripts/run.sh context/scripts/<script>.py [args]`

**General vs Personalized:**
- General-purpose items live in `default-skills/`, `default-scripts/`, and `default-agents/`
- Personalized ones live directly in `context/skills/`, `context/scripts/`, and `context/agents/`
- The context folders have symlinks to the defaults, so all are accessible from one place

### Skill and Script Maintenance

You have an active role in maintaining and improving skills and scripts. When you identify any problems, gaps, or issues with a skill or script, you should:

1. Think about how to address and fix that issue.
2. Present options to the user for addressing and fixing the problem.
3. Offer to spin up a nested agent to work on that specific skill or script improvement.

This ensures that the assistant is always evolving and that skills/scripts remain up-to-date and effective.

### Writing Skills

- Format: YAML frontmatter + markdown instructions
- Never use literal backtick command syntax in SKILL.md (triggers permission prompts)
- Variable substitution: `$ARGUMENTS`, `$0`/`$1`/`$2`, `${CLAUDE_SESSION_ID}`

### Testing

Run the full suite: `context/scripts/run.sh -m pytest tests/ -v`

Write tests alongside code. Mock external dependencies with `unittest.mock`.

### Browser Automation

Chrome DevTools MCP provides full browser control. Use `/debug-app` for integrated frontend testing.

### Compact Instructions

When compacting, preserve:
- Current task context and progress
- Key decisions made during this session
- Key learnings from this session
- Any unresolved questions or blockers
