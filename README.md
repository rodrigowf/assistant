# Personal Assistant

**A transparent, hackable AI assistant that evolves with you.**

Most AI assistants are black boxesâ€”frozen binaries that do what they do and nothing more. This one is different: it's ~6,400 lines of readable code that you can understand, modify, and extend. It can chat, execute commands, remember context, coordinate multiple AI agents, and even edit its own source code while running.

The entire system runs locally. Your conversations, memory, and credentials never leave your machine.

---

## What Makes This Special

### ğŸ” **Radical Transparency**
The entire codebase is small enough to read in an afternoon:
- **Backend**: ~2,400 lines of Python (orchestrator + API + Claude SDK wrapper)
- **Frontend**: ~4,000 lines of TypeScript/React (multi-tab UI with voice)

No enterprise frameworks, no hidden abstraction layers. Every line that touches your files or executes commands is right there to inspect.

### ğŸ­ **Multi-Agent Orchestration**
An orchestrator agent coordinates multiple Claude Code instances simultaneously. It's like having a conductor who thinks strategically while specialized agents execute deeply:
- Break complex tasks into parallel workstreams
- Delegate work to specialized agents (code review, testing, documentation)
- Search across all past conversations for relevant context
- Each agent appears as its own tab in the browser UI

This mirrors how humans actually work on complex projectsâ€”you don't context-switch constantly, you coordinate parallel efforts.

### ğŸ¤ **Voice-First, Actually**
Talk to the orchestrator naturally via WebRTC with sub-100ms latency:
- Audio streams directly browser â†” OpenAI (no backend relay)
- Server-side voice activity detection (no push-to-talk)
- Interrupt by speaking (barge-in support)
- Tool calls work during voice (e.g., "open two agent sessions")
- Voice and text share the same conversation history

Voice isn't bolted onâ€”it's a first-class interface that feels native.

### ğŸ§  **Persistent Memory**
The system maintains searchable memory across all sessions:
- **Agent memory**: Patterns, preferences, and decisions learned over time
- **Orchestrator memory**: Cross-session project context
- **Conversation history**: Every past interaction, semantically indexed

Memory and history are indexed automatically in the background using ChromaDB + sentence-transformers. Search via `/recall <query>` or the orchestrator searches proactively when relevant.

### ğŸ› ï¸ **Self-Modifying**
The assistant can edit its own capabilities:
- Fix bugs in the UI (while running in that UI)
- Add new tools to the orchestrator
- Create custom skills (slash commands) from workflows
- Modify the wrapper application's source code
- Changes hot-reload automatically

Teach it something once, and it can codify that knowledge into a reusable automation.

---

## What It Can Do

### Regular Agent Sessions
- Execute code, manage files, run shell commands
- Full Claude Code capabilities in each tab
- Stream responses with thinking blocks and tool execution visible
- Real-time cost and token tracking

### Orchestrator Coordination
- **Open multiple agents**: `"Open two agentsâ€”one writes tests, the other writes implementation"`
- **Delegate tasks**: `"Have an agent refactor auth while we discuss the API design"`
- **Search context**: `"What was I working on yesterday?"`
- **Read agent history**: Monitor what each agent is doing in real-time
- **Dynamic tab management**: Agent tabs auto-spawn when opened, auto-close when terminated

### Voice Conversations
- Talk to the orchestrator naturally (no clicking)
- Audio level visualization (mic + speaker)
- Live status indicators (listening, thinking, speaking, tool use)
- Mic mute toggle
- Seamless text â†” voice mode switching

### Memory & Search
- Semantic search over all past conversations
- Search memory files for project context
- Results ranked by relevance (distance threshold: 1.5)
- Automatic background indexing (memory: instant, history: 2-min intervals)

### Custom Skills
Define workflows as YAML + markdown:
```yaml
# context/skills/standup/SKILL.md
---
name: standup
description: Run my morning routine
---

1. Check calendar for today's meetings
2. Summarize unread Slack messages
3. List PRs waiting for review
```

Type `/standup` and it runs. Ask the assistant to "turn this into a skill" after showing it a workflow.

---

## Architecture Overview

```
assistant/
â”œâ”€â”€ orchestrator/     # Orchestrator agent (~800 lines)
â”‚   â”œâ”€â”€ agent.py      # Main loop with tool execution
â”‚   â”œâ”€â”€ session.py    # JSONL persistence, dual-mode support
â”‚   â”œâ”€â”€ providers/    # Anthropic (text) + OpenAI (voice)
â”‚   â””â”€â”€ tools/        # 8 tools: agent control, search, files
â”œâ”€â”€ api/              # FastAPI backend (~1000 lines)
â”‚   â”œâ”€â”€ app.py        # Server with WebSocket routes
â”‚   â”œâ”€â”€ pool.py       # Unified session pool
â”‚   â”œâ”€â”€ indexer.py    # Background memory/history indexing
â”‚   â””â”€â”€ routes/       # REST + WebSocket endpoints
â”œâ”€â”€ manager/          # Claude SDK wrapper (~600 lines)
â”‚   â”œâ”€â”€ session.py    # Dual ID system, event streaming
â”‚   â””â”€â”€ store.py      # JSONL session reader
â”œâ”€â”€ frontend/         # React multi-tab UI (~4000 lines)
â”‚   â”œâ”€â”€ context/      # TabsContext (global state)
â”‚   â”œâ”€â”€ hooks/        # useChatInstance, useVoiceOrchestrator
â”‚   â””â”€â”€ components/   # ChatPanel, VoiceButton, TabBar
â”œâ”€â”€ default-skills/   # General-purpose skills (shareable)
â”œâ”€â”€ default-scripts/  # General-purpose scripts (shareable)
â”œâ”€â”€ default-agents/   # General-purpose agents (shareable)
â”œâ”€â”€ context/          # PRIVATE - Git submodule (assistant-context repo)
â”‚   â”œâ”€â”€ *.jsonl       # Session files (SDK writes directly)
â”‚   â”œâ”€â”€ <uuid>/       # SDK state dirs (subagents, tool-results)
â”‚   â”œâ”€â”€ memory/       # Memory markdown files
â”‚   â”œâ”€â”€ skills/       # Symlinks to default-skills + personalized
â”‚   â”œâ”€â”€ scripts/      # Symlinks to default-scripts + personalized
â”‚   â”œâ”€â”€ agents/       # Symlinks to default-agents + personalized
â”‚   â”œâ”€â”€ secrets/      # OAuth credentials and tokens
â”‚   â””â”€â”€ .env          # Environment variables
â”œâ”€â”€ utils/            # Shared Python utilities (paths.py)
â””â”€â”€ .claude_config/   # SDK config (symlink to context/)
```

### Key Design Decisions

**Dual Session IDs**: Each session has two IDs:
- `local_id`: Stable UUID from frontend (primary key everywhere)
- `sdk_session_id`: Claude SDK's ID (for JSONL files and resume)

This eliminated the "triple-ID-change problem" where tabs would go: `new-N` â†’ placeholder UUID â†’ SDK UUID.

**Headless Instances**: Tab state is separated from presentation. All tabs stay mounted (with `display: none`) to preserve WebSocket/WebRTC connections when inactive. Tab switching is instant.

**Event-Queue Voice**: Frontend mirrors OpenAI Realtime events to backend via WebSocket. Backend only handles tool executionâ€”audio never touches the server. This keeps latency sub-100ms.

**Single Orchestrator**: Only one orchestrator can be active at a time (enforced via modal). This prevents conflicting commands to agent sessions and maintains a clear mental model.

---

## Installation

The assistant is **ready to deploy** on any machine with the prerequisites installed. The installation script handles everything automatically.

### Prerequisites

- **Python 3.12+**
- **Node.js 20+**
- **Claude Code CLI** â€” `npm install -g @anthropic-ai/claude-code && claude auth login`
- **API Keys** â€” `ANTHROPIC_API_KEY` (required), `OPENAI_API_KEY` (for voice mode)

Check prerequisites:
```bash
./default-scripts/install-prerequisites.sh
```

### One-Command Installation

```bash
git clone https://github.com/rodrigowf/assistant.git
cd assistant
./install.sh
```

The interactive installer will:
1. âœ“ Check system prerequisites (Python, Node.js, Claude CLI)
2. âœ“ Set up your context (fresh install or import existing)
3. âœ“ Create symlinks to default skills, scripts, and agents
4. âœ“ Configure Claude SDK compatibility
5. âœ“ Install Python dependencies (FastAPI, ChromaDB, etc.)
6. âœ“ Install frontend dependencies (React, Vite)
7. âœ“ Verify the installation

**Installation Options:**
```bash
./install.sh                                    # Interactive (recommended)
./install.sh --new-context                      # Fresh install, no prompts
./install.sh --import-context URL               # Import existing context repo
./install.sh --dev                              # Include dev dependencies
./install.sh --skip-prereqs                     # Skip prerequisite checks
```

### Run

```bash
# Terminal 1 â€” Backend
context/scripts/run.sh -m uvicorn api.app:create_app --factory --port 8000

# Terminal 2 â€” Frontend
cd frontend && npm run dev
```

Open **https://localhost:5173** and start chatting.

**Tip**: Use `/debug-app` to launch both backend and frontend with browser automation.

### Migrate to Another Machine

Your personal data lives in `context/` (conversations, memory, credentials). To migrate:

1. **If context is a git repo**: Push to private remote, then on new machine:
   ```bash
   ./install.sh --import-context git@github.com:you/assistant-context.git
   ```

2. **Manual migration**: Copy `context/` folder to new machine, then run `./install.sh`

3. **Copy remaining secrets** (not in git):
   - `context/secrets/` â€” OAuth tokens
   - `context/.env` â€” API keys
   - `context/certs/` â€” SSL certificates

---

## Using the Multi-Tab Interface

The web UI is a multi-tab browser application inspired by modern code editors.

### Regular Agent Sessions
Click "New Session" in the sidebar to open a Claude Code agent. Each session appears as a tab. You can:
- Open multiple sessions simultaneously
- Switch between tabs without losing state
- Rename sessions (click the pencil icon in sidebar)
- Delete old sessions (click the Ã— icon)
- Resume past sessions from history

Sessions persist across browser refreshâ€”if you close and reopen, active sessions reconnect automatically.

### Orchestrator Tab
Click the **âœ¦** button in the sidebar to open the orchestrator. This is a special agent that can coordinate all other sessions.

**What the orchestrator can do:**
- `list_agent_sessions` â€” See all active sessions
- `open_agent_session` â€” Create or resume agent sessions (tabs auto-spawn)
- `close_agent_session` â€” Terminate sessions (tabs auto-close)
- `send_to_agent_session` â€” Delegate work and wait for responses
- `read_agent_session` â€” Read conversation history
- `list_history` â€” List all past sessions with metadata
- `search_history` â€” Semantic search over conversations
- `search_memory` â€” Semantic search over memory files
- `read_file` / `write_file` â€” File operations

**Example workflows:**
- "Open two agentsâ€”one writes tests, the other writes the implementation. Have them work in parallel."
- "Search my history for how we handled authentication last time, then apply the same pattern here."
- "Open an agent to refactor the user module while we discuss the new API design here."

### Voice Mode (Orchestrator Only)
Click the microphone button in the orchestrator tab to start voice conversation.

**Features:**
- **No push-to-talk**: Server-side VAD detects when you're speaking
- **Interrupt anytime**: Start speaking and the assistant stops (barge-in)
- **Tool calls work**: Say "open two agent sessions" and they spawn
- **Shared history**: Voice transcripts appear inline with text messages
- **Audio visualization**: See mic input and speaker output levels in real-time

**States shown in UI:**
- **Connecting**: Establishing WebRTC
- **Active**: Listening for your voice
- **Speaking**: Assistant is responding
- **Thinking**: Processing your request
- **Tool use**: Executing a tool (e.g., opening sessions)
- **Error**: Connection failed (check `OPENAI_API_KEY`)

---

## Skills: Extensible Automation

Skills are YAML + markdown files in the `context/skills/` directory. They define slash commands that the assistant executes.

### Built-in Skills

| Command | Purpose |
|---------|---------|
| `/recall <query>` | Search memory and past conversations semantically |
| `/scaffold-skill` | Create a new skill from a workflow description |
| `/scaffold-agent` | Define a specialized agent with custom system prompt |
| `/debug-app` | Launch backend + frontend with browser automation |
| `/keybindings-help` | Customize keyboard shortcuts |
| `/wrapper-guide` | Understand the wrapper application internals |

### Creating Custom Skills

Ask the assistant to create a skill:
```
"Turn this into a skill that runs my morning standup:
1. Check calendar for today's meetings
2. Summarize unread Slack messages
3. List PRs waiting for my review"
```

Or manually create `context/skills/standup/SKILL.md`:
```yaml
---
name: standup
description: Run my morning routine
---

1. Use the Bash tool to run `gcal today` and show today's meetings
2. Use the Bash tool to run `slack-cli unread` and summarize
3. Use the Bash tool to run `gh pr list --author @me` and format as table
```

Type `/standup` to run it.

---

## Memory System

The assistant maintains two types of memory:

### Agent Memory
- **Location**: `context/memory/MEMORY.md`
- **Purpose**: Index file with references to detailed docs
- **Pattern**: Keep MEMORY.md under 200 lines with one-line references
- **Details**: Store detailed plans, decisions, and context in separate `.md` files
- **Indexing**: Instant (file watcher with 1s debounce)

Example structure:
```
memory/
â”œâ”€â”€ MEMORY.md                   # Index (one-line references)
â”œâ”€â”€ project-overview.md         # Detailed project docs
â”œâ”€â”€ multi-tab-plan.md           # Frontend implementation notes
â””â”€â”€ complete-system-analysis.md # Analysis and improvement ideas
```

### Orchestrator Memory
- **Location**: `context/memory/ORCHESTRATOR_MEMORY.md`
- **Purpose**: Cross-session context for the orchestrator
- **Usage**: Orchestrator reads this before each session start
- **Auto-indexed**: Yes (same as agent memory)

### Conversation History
- **Format**: JSONL files (one per session)
- **Indexing**: Every 2 minutes (if files changed)
- **Search**: Via `/recall` or orchestrator `search_history` tool
- **Cleanup**: Deleted sessions removed from index automatically

---

## Configuration

### Session Settings (`.manager.json`)
```json
{
  "model": "claude-sonnet-4-20250514",
  "permission_mode": "default",
  "max_budget_usd": 10.0,
  "max_turns": 50
}
```

### Environment Variables
```bash
# Required
ANTHROPIC_API_KEY=sk-...        # Claude SDK
OPENAI_API_KEY=sk-...           # Voice mode

# Optional
CLAUDE_CONFIG_DIR=.claude_config       # Local data directory
ORCHESTRATOR_MODEL=claude-sonnet-4-6   # Orchestrator model
ORCHESTRATOR_MAX_TOKENS=8192           # Max tokens per turn
```

---

## Philosophy

### Transparency Over Polish
The codebase is intentionally small and readable. You should understand how it works in an afternoon. No hidden magic, no enterprise frameworks, no vendor lock-in.

### Developer-Native
This isn't a chatbot bolted onto Slack or Discord. It's a proper development environment designed for people who think in code and want to extend their tools.

### Self-Improving
The assistant can modify itself. Fix bugs, add features, create skillsâ€”all while running. You're building a tool that grows with you, not adapting to someone else's vision.

### Local-First
Your conversations, memory, and credentials stay on your machine. No cloud sync, no third-party platforms, no account required beyond API keys.

---

## Development

### Setup with Dev Dependencies
```bash
./install.sh --dev
```

### Run Tests
```bash
context/scripts/run.sh -m pytest tests/ -v
```

### Lint and Type Check
```bash
.venv/bin/ruff check .
.venv/bin/mypy api manager orchestrator
```

### Frontend Development
```bash
cd frontend
npm run dev       # Start dev server
npm run build     # Production build
npm run lint      # ESLint
```

---

## API Endpoints

### Sessions
- `GET /api/sessions` â€” List all sessions (JSONL + live pool status)
- `GET /api/sessions/pool/live` â€” Active sessions (for reconnect after refresh)
- `GET /api/sessions/{session_id}` â€” Session detail with messages
- `PATCH /api/sessions/{session_id}/rename` â€” Rename session
- `DELETE /api/sessions/{session_id}` â€” Delete session (removes JSONL + index)

### WebSockets
- `WS /api/sessions/chat` â€” Agent session WebSocket
- `WS /api/orchestrator/chat` â€” Orchestrator WebSocket

### Voice
- `POST /api/orchestrator/voice/session` â€” Get ephemeral OpenAI token

---

## How It Works

### Regular Agent Flow
1. User sends message â†’ Frontend (React) with stable `local_id`
2. Frontend â†’ WebSocket (`/api/sessions/chat`) â†’ SessionPool
3. Pool â†’ SessionManager â†’ Claude SDK
4. Claude streams response â†’ Pool broadcasts to all subscribers
5. Events rendered in ChatPanel with real-time updates

### Orchestrator Flow (Text)
1. User sends message â†’ Frontend with `local_id`
2. Frontend â†’ Orchestrator WebSocket
3. OrchestratorSession â†’ AnthropicProvider
4. Tool calls executed (e.g., open agent session)
5. Results streamed back to frontend
6. Agent tabs auto-spawn when sessions opened

### Orchestrator Flow (Voice)
1. Frontend establishes WebRTC to OpenAI (via ephemeral token)
2. User speaks â†’ OpenAI Realtime API
3. Events mirrored to backend via orchestrator WebSocket
4. Backend processes tool calls, sends results back as `voice_command`
5. Frontend forwards results to OpenAI via data channel
6. Assistant responds with voice (audio direct from OpenAI)

### Session Persistence
1. On browser refresh, frontend calls `GET /api/sessions/pool/live`
2. Backend returns all active sessions with `local_id` + `sdk_session_id`
3. Frontend reopens tabs using original `local_id` values
4. Sessions seamlessly reconnect via WebSocket

---

## Production Readiness

### âœ… Ready to Deploy

The assistant is **production-ready** and can be deployed on any machine:

| Feature | Status |
|---------|--------|
| Multi-tab frontend with voice | âœ… Complete |
| Orchestrator agent (text + voice) | âœ… Complete |
| Session persistence & resumption | âœ… Complete |
| Semantic search (memory + history) | âœ… Complete |
| Background indexing | âœ… Complete |
| Cost and usage tracking | âœ… Complete |
| Dynamic agent tab management | âœ… Complete |
| WebRTC voice mode | âœ… Complete |
| **One-command installation** | âœ… Complete |
| **Public/private separation** | âœ… Complete |
| **Cross-machine migration** | âœ… Complete |

### ğŸ¯ Deployment Options

- **Local workstation** â€” Run on your development machine
- **Home server** â€” Deploy on a Mac Mini, NUC, or similar
- **Cloud VM** â€” AWS EC2, GCP, Azure, DigitalOcean
- **Headless server** â€” Backend-only for API access

### ğŸ” Data Portability

Your data is fully portable via the `context/` folder:
- Initialize as a private git repo for version control
- Import on any machine with `./install.sh --import-context URL`
- Symlinks to framework skills/agents are created automatically
- Personal skills, memory, and conversations travel with you

---

## Known Limitations

See `memory/complete-system-analysis.md` for detailed analysis, but high-level:

1. **Error Recovery**: No auto-reconnect on WebSocket failure, no retry logic
2. **Observability**: Limited structured logging, no performance dashboard
3. **Context Management**: No auto-summarization (except voice mode), manual memory updates
4. **Agent Coordination**: Handoffs feel abrupt, no "report back" button
5. **Voice Polish**: No wake word, no live transcription, interruption has 300ms lag

These are all solvable and documented in memory with implementation suggestions.

---

## Future Ideas

See `memory/complete-system-analysis.md` for full brainstorm, but top picks:

1. **Proactive Memory System** â€” Auto-extract decisions, ask "should I remember this?"
2. **Agent Templates** â€” Pre-configured agents (code-review, debugger, docs-writer)
3. **Collaborative Sessions** â€” Multiple humans + agents in one conversation
4. **Workflow Automation DSL** â€” Define multi-step workflows declaratively
5. **Explain Mode** â€” Toggle that makes orchestrator explain every decision

---

## License

MIT

---

## Contributing

This is a personal project, but ideas and suggestions are welcome. Open an issue to discuss before submitting a PR.

The goal is to keep the codebase small, readable, and hackableâ€”not to become a framework with every feature imaginable.
